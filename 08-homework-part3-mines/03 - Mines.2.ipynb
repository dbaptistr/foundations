{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping mine data with `.apply`\n",
    "\n",
    "## The pages we'll be looking at\n",
    "\n",
    "If I wanted to read specific information about a specfic mine, it takes a few steps. **Do these steps with your browser before you try any programming.**\n",
    "\n",
    "1. Visit the [Mine Data Retrieval System](https://arlweb.msha.gov/drs/drshome.htm)\n",
    "2. Scroll down to **Mine Identification Number (ID) Search**\n",
    "3. Type in a mine ID number, such as `3503598`, click **Search**\n",
    "4. I'm on a page! It lists the MINE NAME and MINE OWNER.\n",
    "\n",
    "After searching for and finding a mine, I can use this page to **find reports about this mine**. Some of the reports are on accidents, violations, inspections, health samples and more. To get those reports:\n",
    "\n",
    "1. Search for a mine (if you haven't already)\n",
    "2. Scroll down and change **Beginning Date** to `1/1/1995` (violation reports begin in 1995, accidents begin in 1983)\n",
    "3. Select the report type of `Violations`\n",
    "4. Click **Get Report**\n",
    "5. I'm on a page! It lists ALL OF THE MINE'S VIOLATIONS.\n",
    "\n",
    "By changing the report type you're searching for you can find all sorts of different data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing this programmatically\n",
    "\n",
    "## First, scraping a single page\n",
    "\n",
    "### Import your imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for a mine\n",
    "\n",
    "Visit the [Mine Data Retrieval System](https://arlweb.msha.gov/drs/drshome.htm) and use Selenium to search for `3503598`\n",
    "\n",
    "- *TIP: You might need to use the Selenium code to scroll down to the right spot on the page. Or not!*\n",
    "- *TIP: Use `.send_keys` to type into the box*\n",
    "- *TIP: On pages that never change, you can usually just use XPath if you're feeling lazy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://arlweb.msha.gov/drs/drshome.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = driver.find_element_by_name('MineId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"arguments[0].scrollIntoView(true)\", text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input.send_keys('3503598')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element_by_xpath('//*[@id=\"content\"]/table[3]/tbody/tr[3]/td[2]/input')\n",
    "button.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding reports\n",
    "\n",
    "On the \"Report Selection Page\" (where you should be after you search), use Selenium to...\n",
    "\n",
    "- Change the **Beginning Date** to `1/1/1995`\n",
    "- Select the report type of `Violations`\n",
    "- Click **Get Report**\n",
    "\n",
    ".\n",
    "\n",
    "- *TIP: Remember, if someone isn't on the page Selenium can't click it!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_input = driver.find_element_by_name('BDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_input.send_keys('1/1/1995')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_button = driver.find_element_by_xpath('//*[@id=\"content\"]/form[1]/table[3]/tbody/tr[2]/td[2]/table/tbody/tr[1]/td/input')\n",
    "violations_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_button = driver.find_element_by_xpath('//*[@id=\"content\"]/form[1]/table[3]/tbody/tr[3]/td[2]/input')\n",
    "report_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving reports\n",
    "\n",
    "Save all of the rows of data on that page into a new dataframe. Each column is its own column, **and you also need to save the URL under the 'Standard' column.** Here, I even made you a blank dictionary:\n",
    "\n",
    "```python\n",
    "data = {}\n",
    "data['violator'] = ''\n",
    "data['contract_id'] = ''\n",
    "data['citation_no'] = ''\n",
    "data['case_no'] = ''\n",
    "data['date_issues'] = ''\n",
    "data['final_order_date'] = ''\n",
    "data['section_of_act'] = ''\n",
    "data['date_terminated'] = ''\n",
    "data['citation'] = ''\n",
    "data['s_and_s'] = ''\n",
    "data['standard'] = ''\n",
    "data['standard_url'] = ''\n",
    "data['proposed_penalty'] = ''\n",
    "data['citation_status'] = ''\n",
    "data['current_penalty'] = ''\n",
    "data['amount_paid'] = ''\n",
    "```\n",
    "\n",
    "- *TIP: Some of those table rows aren't what you want. How can you tell them apart from the good ones? (the previous mine owner ones are okay, I just mean the weird headers)*\n",
    "- *TIP: I sense `.find_elements` + a lot of square brackets*\n",
    "- *TIP: This is just like scraping a search results page!*\n",
    "- *TIP: For the URL, you'll need to find the `a` inside of the cell*\n",
    "- *TIP: class name is sadly not going to save your life here, because some of the `tr`s and `td`s have the same class! It's stupid. But there's a trick: CSS selectors! Something like `div#container` finds a `div` with the id of `container`, while `span.important` finds a `span` with the class of `important`. It should be helpful! And use `.find_elements_by_` + tab to see what the command is*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newberg Rock & Dirt    8790964   000383840 4/13/2015 7/17/2015  104(a) 4/15/2015 C N 56.4101 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8790962   000383840 4/10/2015 7/17/2015  104(a) 4/10/2015 C N 56.14107(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8790963   000383840 4/10/2015 7/17/2015  104(a) 4/13/2015 C Y 56.15020 873.00 Closed 873.00  873.00 \n",
      "Newberg Rock & Dirt    8694458   000345066 1/29/2014 4/12/2014  104(a) 1/29/2014 C N 56.12018 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8694457   000345066 1/29/2014 4/12/2014  104(a) 1/29/2014 C N 56.12004 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8694456   000345066 1/28/2014 4/12/2014  104(a) 1/29/2014 C N 56.14132(b)(1) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8694454   000345066 1/28/2014 4/12/2014  104(a) 1/29/2014 C Y 56.12032 243.00 Closed 243.00  243.00 \n",
      "Newberg Rock & Dirt    8694455   000345066 1/28/2014 4/12/2014  104(a) 1/29/2014 C N 56.12004 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8694451   000347758 1/28/2014 5/14/2014  104(a) 1/29/2014 C N 56.14100(b) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8694452   000345066 1/28/2014 4/12/2014  104(a) 1/29/2014 C N 56.14132(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8694450   000345066 1/28/2014 4/12/2014  104(a) 1/29/2014 C N 56.14132(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8694453   000345066 1/28/2014 4/12/2014  104(a) 1/29/2014 C N 56.4201(a)(1) 100.00 Closed 100.00  100.00 \n",
      " \n",
      "\n",
      "Newberg Rock & Dirt    8599789   000297041 5/1/2012 9/13/2012  104(a) 5/7/2012 C Y 56.14101(a)(2) 243.00 Closed 243.00  243.00 \n",
      "Newberg Rock & Dirt    8599787   000291331 5/1/2012 7/13/2012  104(a) 5/7/2012 C N 56.14108 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8599788   000291331 5/1/2012 7/13/2012  104(a) 5/7/2012 C N 56.12004 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8599107   000269626 9/7/2011 11/18/2011  104(a) 9/19/2011 C N 50.30(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8599025   000239613 10/7/2010 1/5/2011  104(a) 10/7/2010 C N 56.12004 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    8599026   000239613 10/7/2010 1/5/2011  104(a) 10/7/2010 C N 56.12004 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6398905   000220925 4/20/2010 7/9/2010  104(a) 6/8/2010 C Y 56.11001 117.00 Closed 117.00  117.00 \n",
      "Newberg Rock & Dirt    6338509   000210055 12/29/2009 1/10/2013  104(a) 1/11/2010 C N 56.14107(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6338508   000210055 12/29/2009 1/10/2013  104(a) 12/30/2009 C N 56.11002 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6338507   000210055 12/29/2009 1/10/2013  104(a) 1/11/2010 C N 56.14107(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6338511   000210055 12/29/2009 1/10/2013  104(a) 1/11/2010 C N 56.14107(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6338512   000210055 12/29/2009 1/10/2013  104(a) 12/29/2009 C N 56.12004 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6338510   000210055 12/29/2009 1/10/2013  104(a) 12/30/2009 C N 56.14107(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6479620   000180614 2/26/2009 5/8/2009  104(a) 3/4/2009 C N 56.12028 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6479614   000180614 2/26/2009 5/22/2010  104(a) 3/4/2009 C N 56.14100(d) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6479618   000180614 2/26/2009 5/22/2010  104(a) 3/4/2009 C N 56.14130(i) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6479612   000180614 2/26/2009 5/22/2010  104(a) 3/4/2009 C Y 56.9200(d) 263.00 Closed 263.00  263.00 \n",
      "Newberg Rock & Dirt    6479616   000180614 2/26/2009 5/22/2010  104(a) 3/4/2009 C N 56.14103(b) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6479617   000180614 2/26/2009 5/8/2009  104(a) 3/4/2009 C N 56.4201(a)(2) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6479615   000180614 2/26/2009 5/22/2010  104(a) 3/4/2009 C N 56.14100(b) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6479613   000180614 2/26/2009 5/22/2010  104(a) 2/26/2009 C Y 56.3200 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6479619   000180614 2/26/2009 5/22/2010  104(a) 2/26/2009 C N 56.14100(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6430326   000152001 4/2/2008 7/10/2008  104(a) 4/3/2008 C N 56.14100(b) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6430325   000152001 4/2/2008 7/10/2008  104(a) 4/3/2008 C N 56.14112(a)(1) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6342892   000121048 5/23/2007 8/17/2007  104(a) 5/24/2007 C N 56.14100(b) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6342895   000121048 5/23/2007 8/17/2007  104(a) 5/24/2007 C N 56.14107(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6342894   000121048 5/23/2007 8/17/2007  104(a) 5/24/2007 C N 56.14132(a) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6342893   000121048 5/23/2007 8/17/2007  104(a) 5/24/2007 C N 56.14100(b) 100.00 Closed 100.00  100.00 \n",
      "Newberg Rock & Dirt    6383438   000086543 3/1/2006 6/16/2006  104(a) 3/2/2006 C N 56.11002 60.00 Closed 60.00  60.00 \n",
      "Newberg Rock & Dirt    6383437   000086543 3/1/2006 6/16/2006  104(a) 3/2/2006 C N 56.14107(a) 60.00 Closed 60.00  60.00 \n",
      "Newberg Rock & Dirt    6368407   000051247 10/27/2004 7/23/2005  104(a) 1/21/2005 C N 62.120 60.00 Closed 60.00  60.00 \n",
      "Newberg Rock & Dirt    6368406   000044260 10/25/2004 1/12/2005  104(a) 10/27/2004 C Y 56.14131(a) 99.00 Closed 99.00  99.00 \n"
     ]
    }
   ],
   "source": [
    "data_table1 = driver.find_elements_by_tag_name('tr')\n",
    "\n",
    "for info in data_table1[36:]:\n",
    "    print(info.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newberg Rock & Dirt\n",
      "  \n",
      "8790964  \n",
      "000383840\n",
      "4/13/2015\n",
      "7/17/2015 \n",
      "104(a)\n",
      "4/15/2015\n",
      "C\n",
      "N\n",
      "56.4101\n",
      "100.00\n",
      "Closed\n",
      "100.00 \n",
      "100.00 \n"
     ]
    }
   ],
   "source": [
    "data_table2 = data_table1[36].find_elements_by_tag_name('td')\n",
    "\n",
    "for info in data_table2:\n",
    "    print(info.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Newberg Rock & Dirt'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_table2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join everything in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8570415611a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_table1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_tag_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_table1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "data_table1 = driver.find_elements_by_tag_name('tr')\n",
    "\n",
    "for info in data_table1[36:]:\n",
    "    data_table2 = info.find_elements_by_tag_name('td')\n",
    "\n",
    "data['violator'] = data_table2[0].text\n",
    "data['contract_id'] = data_table2[1].text\n",
    "data['citation_no'] = data_table2[2].text\n",
    "data['case_no'] = data_table2[3].text\n",
    "data['date_issues'] = data_table2[4].text\n",
    "data['final_order_date'] = data_table2[5].text\n",
    "data['section_of_act'] = data_table2[6].text\n",
    "data['date_terminated'] = data_table2[7].text\n",
    "data['citation'] = data_table2[8].text\n",
    "data['s_and_s'] = data_table2[9].text\n",
    "data['standard'] = data_table2[10].text\n",
    "data['standard_url'] = data_table2[10].find_element_by_xpath('//*[@id=\"anch_66\"]').get_attribute('href')  \n",
    "data['proposed_penalty'] = data_table2[11].text\n",
    "data['citation_status'] = data_table2[12].text\n",
    "data['current_penalty'] = data_table2[13].text\n",
    "data['amount_paid'] = data_table2[14].text\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving that data\n",
    "\n",
    "Save the dataframe to a CSV file called `3503598-violations.csv` (that's the TDLR code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put that all in ONE cell that runs correctly\n",
    "\n",
    "The **entire process**, from searching to saving as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using .apply to find data about SEVERAL mines\n",
    "\n",
    "The file `mines-subset.csv` has a list of mine IDs. We're going to scrape the operator's name for each of those mines.\n",
    "\n",
    "### Open up `mines-subset.csv` and save it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open up `mines-subset.csv` in a text editor, then look at your dataframe. Is something different about them? If so, make them match.\n",
    "\n",
    "- *TIP: You can zero fill if you want, but another option is that when reading in a CSV, `dtype='str'` will force everything to be a string*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert your one-cell scraper into a function, and use it on each row of our dataset\n",
    "\n",
    "- *TIP: You'll be using `.apply`*\n",
    "- *TIP: You won't be joining this back into your dataframe, so you don't need to `return` anything or `join` or any of that.*\n",
    "- *TIP: Be careful of your **other variable names** - if you're calling the thing you're sending your function `row`, you can't use it anywhere else (like in your loop)*\n",
    "- *TIP: **BE CAREFUL WHAT YOU NAME YOUR DATAFRAMES.** If you name the citations dataframe `df` it can overwrite your mine ID `df`*\n",
    "- *TIP: You'll be saving a dataframe each time*\n",
    "- *TIP: Be sure you change everything that refers to the mine ID to refer to the current row's ID instead of `3503598`*\n",
    "- *TIP: BE SURE TO CHANGE EVERYTHING THAT REFERS TO THE MINE ID*\n",
    "- *TIP: EVERYTHING, EVERYTHING, EVERYTHING! Look at the end of your function! Maybe I'm overreacting, I don't know.*\n",
    "- *TIP: If you hit an error about list index out of range, see what line it's happening on and go look at the page. What's different about this page than the previous ones? (answer: the last three columns!) If you assign those columns later using `try`/`except` you should be able to get some data from those rows without throwing it all out. If you can't figure it out, just wrap it all in try/except and give up on those rows*\n",
    "- *TIP: Some of the standards might not have links, either, so you might want to wrap that in a `try`/`except`, too!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay, now do it for ALL of the mines\n",
    "\n",
    "Open up `mines.csv` using pandas and do the same thing, it will just be for more mines this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
